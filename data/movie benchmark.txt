201904new:
# TF：
    #xavier_init; lr=0.002; no L2.
    # FM avg=0.94162
    # LR avg=0.96164
    # DNNavg=0.9523
    # FieldDNN=0.9619

    # Wide:          EPOCH=150 LR=0.001 0.9626 0.9627
    # Deep(10,10)    EPOCH=150 LR=0.001 0.9534 0.9550 [0.9663x激活]
    # Wide&Deep:     EPOCH=150 LR=0.001 0.9527 0.9542 0.9588 0.9596 0.9612 ; EPOCH=150 LR=0.0005 0.9507 0.9521 0.9537 0.9533 0.9538 0.9607 0.9628
    # AVG 0.001LR=0.9573 / 0.0005LR=0.9553   #pd.Series([float(i) for i in "0.9507 0.9521 0.9537 0.9533 0.9538 0.9607 0.9628".split(" ")]).mean()

    #Deep(10,10) lr0.001 MEAN=0.9611 BEST=0.9541 0.95416194,0.9596375,0.96367896,0.9652838,0.96610063,0.9588475,0.95897835,0.96488595,0.9621352,0.9573141,
    #Deep+Wide   lr0.001 MEAN=0.9581 BEST=0.9516 0.95761794,0.9650,0.95778,0.95893,0.95407,0.96138,0.95165,0.95456,0.95796,0.9627469

3-> #Deep(10,10)  lr0.0005 MEAN=0.9526 BEST=0.9469  0.9560482,0.95132154,0.94783217,0.9644138,0.9591737,0.9489759,0.9468578,0.95053107,0.9541365,0.94731116
4-> #Deep+Wide    lr0.0005 MEAN=0.9564 BEST=0.9493 0.95601565,0.953820,0.9520745, 0.9509112,0.95234793,0.96418005,0.9615978,0.9618426,0.9493099,0.9622372,
2-> #Deep+FM      lr0.0005:MEAN=0.9509 BEST=0.9461  [0.9492949, 0.9602662, 0.95251215, 0.95207393, 0.94615424, 0.94697815, 0.9534201, 0.9474273, 0.95077604, 0.95029736]
1-> #Deep+Wide+FM lr0.0005:MEAN=0.9497 BEST=0.9450  [0.9480593, 0.9516951, 0.9508657, 0.9450281, 0.949079, 0.9505722, 0.95087147, 0.95070416, 0.9515439, 0.94895566]

3->#FieldDNN(e20,10,10):   MEAN=0.9557 BEST=0.9502 [0.9593348, 0.95224166, 0.95357233, 0.9642616, 0.95332587, 0.9522401, 0.9571624, 0.9508174, 0.96372133, 0.9501557]
4->#FieldDNN(Embd)+Wide:   MEAN=0.9589 BEST=0.9520 [0.95276886, 0.95402354, 0.95538324, 0.966199, 0.9519791, 0.9525499, 0.9685491, 0.9668559, 0.96609026, 0.9541986]
1->#FieldDNN(Embd)+FM:     MEAN=0.9477 BEST=0.9422 [0.9451019, 0.9461878, 0.9434496, 0.9437016, 0.9485915, 0.9457546, 0.94225216, 0.942883, 0.945795, 0.9728427]
2->#FieldDNN(Embd)+Wide+FM:MEAN=0.9497 BEST=0.9463 [0.9478442, 0.9563259, 0.94867826, 0.9612056, 0.94678885, 0.9484733, 0.9467022, 0.94633967, 0.94688517, 0.94801724]

改进Field_DNN和LR，只用ids输入：
    #LR: 1.0415 为什么不如正常的0.961？值得思考  修改bug后:LR_ 增加了reduce_sum at axis=1 Best Score: 1.1053765
    #FM               0.9613,0.9500   [0.9527672,0.95569927,0.9500226,0.9731106,0.9540914,0.96675104,0.9648452,0.9679305,0.96664655,0.9621126]
    #Deep(e20,10,10): 0.9579 0.9485   [0.9646315, 0.96457046, 0.9651331, 0.9561693, 0.9657518, 0.953225, 0.9517628, 0.9543784, 0.95514125, 0.94852614]
    #Deep+LR:    MEAN=0.9592 0.9501   [0.9612582, 0.95976895, 0.9532099, 0.9658031, 0.9501344, 0.95863473, 0.95315826, 0.96515125, 0.958458, 0.96695334]
    #Deep+LR_:   MEAN=0.9510 0.9408   [0.94129854, 0.95424414, 0.9582963, 0.9503197, 0.94088507, 0.956375, 0.9425513, 0.9542897, 0.9559774, 0.956527]
    #Deep+FM:    MEAN=0.9581 0.9519   [0.95319426, 0.9659179, 0.9583129, 0.9625754, 0.9568584, 0.9555263, 0.9519126, 0.95558035, 0.96644086, 0.95500976]
 #Deep+LR_+FM:   MEAN=0.9476 0.9400   [0.9490024, 0.94657576, 0.9401189, 0.94825876, 0.95636916, 0.95200694, 0.94006425, 0.94265074, 0.94319284, 0.9583263]
 -> #DeepFM超过原始FM，更超过embeddingLookUp的FM啦！

 FM2是等价的FM实现方式：每个field，和平方减平方和(None,k)，最后求和再*0.5
 Deep+LR_+FM2:   MEAN=0.9474 0.9413   [0.94403505, 0.944647, 0.95472664, 0.9430393, 0.9469636, 0.94908786, 0.95835567, 0.9435927, 0.94131535, 0.9480291]
(new computer CPU: LR1.1897~1.19 ;FM 1.02~1.03 GPU:LR1.187~1.19 FM:1.02)
-------------------

#movie lens 1M
    Feature: user_id+ movie_id
         LR: 1.1136   [1.11374,1.11363,1.11355]
   (K=16)FM: 0.8759 0.8725 [0.8725196239314502, 0.8778558374960211, 0.8761410918416856, 0.8767934833900838, 0.8764116537721851]
(2k.k.k)MLP: 0.8909 0.8874 [0.8905830239947838, 0.8876157716859745, 0.8874417751650266, 0.8929219301742843, 0.8958153680910038]
LRWide&Deep: 0.8894 0.8864 [0.8905002132246765, 0.8884505889083766, 0.8942822494084322, 0.8872838225545763, 0.886356520652771]
FMWide&Deep: 0.8876 0.8862 [0.8891306483292881, 0.8864404663254943, 0.8862015399751784, 0.8870562556423719, 0.8892361102224905]
     DeepFM: 0.8915 0.8882 [0.8891181369371052, 0.8885330240937728, 0.8965300496620467, 0.894879262809512, 0.8881970309003999]

--
同参数Feature: user_id+movie_id+gender+age+occ [6040, 3706, 2, 7, 21]
         LR:1.1138
         FM:0.8900 0.8874
        MLP:0.8869 0.8827 [0.8826913429211967, 0.8865704888029944, 0.8894205404233329, 0.8848255771624891, 0.8911240322680413]
FMWide&Deep:0.8826 0.8802 [0.8823739401901824, 0.8837272431277021, 0.8806559122061428, 0.8857936966268322, 0.880220939388758]
     DeepFM:0.8820 0.8801 [0.8826602427265312, 0.8804598394828507, 0.8817998533007465, 0.8800670077529135, 0.8852888055994541]

   ---->AFM:0.8766 0.8739 [0.8756965901278242, 0.8739465453956701, 0.8757859254185157, 0.878804661503321, 0.8788787903664987]  比普通FM好了15个千分点 比最好的DeepFM还高6个千
[new envirment test]
   (GPU)AFM:0.8780
(GPU B=2000)0.8857 0.8848 [0.8861,0.8837,0.8848,0.8876,0.8866] #比b=500差了10个千，是否尝试下BN?
        输出model.全1.
(new computer CPU AFM : [0.877 0.878 0.879 0.880 0.881]| GPU AFM:[0.877,0.876,0.879])
(new computer CPU FM : | GPU FM:MEAN=0.8895 BEST=0.8873 FM无论CPU/GPU就跟旧设备一样. [0.8929,0.8888,0.8895,0.8888,0.8874])
        NFM:0.8855 0.8833 [0.8867756211304967, 0.8886955860294873, 0.8853611725795119, 0.883353234544585, 0.8833889285220375] 比普通FM好了7个千分，但比AFM差8个千（新设备几乎没有影响）.
    DeepAFM:



同特征 对FM减掉依赖
         FM:0.8843 0.8827 [0.8837845201733746, 0.8834048621262176, 0.8850899094267737, 0.8827350067186959, 0.8866759037669701]  比全交叉FM好5个千
FMWide&Deep:0.8821 0.8779 [0.8836640089373046, 0.8844558421569535, 0.8779307045514071, 0.8817171700393097, 0.8827627062797546]  比全交叉FWD好2个千
     DeepFM:0.8798 0.8792 [0.8800812885731082, 0.8791612175446523, 0.879225922838042, 0.8800252790692487, 0.8807229491728771]   比全交叉DFM好3个千
        AFM:0.8825 0.8805 [0.883282467081577, 0.8826788224751436, 0.8825482526911965, 0.880550700048857, 0.8835271959063373]    比全交叉AFM【低】了7个千.说明attention已经capture到了


--
同参数Feature: user_id+movie_id+(gender+age+occ)+(genre) [6040, 3706, 2, 7, 21] 不收敛..? LR~1.117@EPOCH=2/3/4  MLP~1.118@EPOCH=1
--
do_1:+ movie genre 爆炸
do_2:+ FM消除依赖 FM_DependencyEliminate
do_3:+ CIN
--------------------------------

# sklearn:
    Ridge 0.961;
    Lasso 1.122;
    ElasticNet:1.122

# lgb:
    1.00835 (best param: 'max_depth':30,'num_leaves': 200)


下面tf不准：
=====================================
sklearn:
    lr:系数爆炸
    ridge:0.961
    lasso/elasticNet:1.122
lgb:
    1.00835 (best param: 'max_depth':30,'num_leaves': 200 )
tf:
    lr(w l2_norm):1.007 (best param:batch size=500,adam 0.01)
    fm:0.95373  (best param:batch size=500,adam 0.01)

